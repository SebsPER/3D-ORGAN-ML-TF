{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "* Model: voxels-usegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotly fix\n",
    "# from plotly import __version__\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# print(__version__) # requires version >= 1.9.0\n",
    "# init_notebook_mode(connected=True)\n",
    "# iplot([{\"x\": [1, 2, 3], \"y\": [3, 1, 6]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reconstruction.model import LoadModel\n",
    "#from reconstruction.utils.plot import plot_vol, plot_reconstruction\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model\n",
    "# model = LoadModel('arq_dataset', 'data/arq_usegan_extended/', opt='voxels-usegan', evaluate_mode=True)\n",
    "# # Load data\n",
    "# # model._load_full_test_set()\n",
    "# model._load_full_test_set(min_points=1, max_points=4,\n",
    "#                           min_radius=6, max_radius=12)\n",
    "# voxels, voxels_target, labels = model.full_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelNet10/voxels.npy\n",
      "ModelNet10/voxels.npy\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = LoadModel('modelnet10', 'data/arq_usegan_extended/', opt='voxels-usegan', evaluate_mode=True)\n",
    "# Load data\n",
    "model._load_full_test_set()\n",
    "voxels, voxels_target, labels = model.full_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = model.predict(voxels, labels)\n",
    "results_2 = model.predict(results_1, labels)\n",
    "\n",
    "def maskedl1(target, incomplete, result):\n",
    "    incomplete = incomplete.reshape(-1)\n",
    "    target = target.reshape(-1)[incomplete == -1]\n",
    "    result = result.reshape(-1)[incomplete == -1]\n",
    "    l1 = np.abs(target - result)\n",
    "    return np.mean(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "print(labels[0])\n",
    "for lbl in np.unique(labels):\n",
    "    lbl_txt = model.label_encoder.inverse_transform(lbl)\n",
    "    #print(lbl_txt)\n",
    "    t_voxels, t_voxels_target = voxels[labels == lbl], voxels_target[labels == lbl]\n",
    "    t_results_1, t_results_2 = results_1[labels == lbl], results_2[labels == lbl]\n",
    "    l1_input = maskedl1(t_voxels_target, t_voxels, t_voxels)\n",
    "    l1_it1 = maskedl1(t_voxels_target, t_voxels, t_results_1)\n",
    "    l1_it2 = maskedl1(t_voxels_target, t_voxels, t_results_2)\n",
    "    result_df.loc[lbl, 'label'] = lbl_txt[0]\n",
    "    result_df.loc[lbl, 'input_l1'] = l1_input\n",
    "    result_df.loc[lbl, 'result_l1'] = l1_it1\n",
    "    result_df.loc[lbl, 'result2_l1'] = l1_it2\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for lbl in np.unique(labels):\n",
    "    t_input = voxels[labels == lbl]\n",
    "    t_target = voxels_target[labels == lbl]\n",
    "    t_labels = labels[labels == lbl]\n",
    "    t_result = model.predict(t_input, t_labels)\n",
    "#     t_result = model.predict(t, t_labels)\n",
    "    l1 = np.mean(np.abs(t_target - t_result))\n",
    "    l1_original = np.mean(np.abs(t_target - t_input))\n",
    "    print(model.label_encoder.inverse_transform(lbl) + ': %.4f (%.4f)' % (l1, l1_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = pd.read_csv(model.training_log_file)\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(train_log.epoch, train_log.l1_loss_test, '-x', label='l1_test', linewidth=3, alpha=.75)\n",
    "plt.plot(train_log.epoch, train_log.l1_loss_train, '-x', label='l1_train', linewidth=3, alpha=.75)\n",
    "plt.ylim(0.0045, 0.0312)\n",
    "plt.xlim(0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('L1 loss per category (test dataset):')\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for lbl in np.unique(labels):\n",
    "    t_input = voxels[labels == lbl]\n",
    "    t_target = voxels_target[labels == lbl]\n",
    "    t_labels = labels[labels == lbl]\n",
    "    t_result = model.predict(t_input, t_labels)\n",
    "#     t_result = model.predict(t, t_labels)\n",
    "    l1 = np.mean(np.abs(t_target - t_result))\n",
    "    l1_original = np.mean(np.abs(t_target - t_input))\n",
    "    print(model.label_encoder.inverse_transform(lbl) + ': %.4f (%.4f)' % (l1, l1_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._evaluate(model.full_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = model.label_encoder.transform(['arq'])[0]\n",
    "arq_voxels = voxels[labels == lbl]\n",
    "arq_voxels_target = voxels_target[labels == lbl]\n",
    "arq_labels = labels[labels == lbl]\n",
    "arq_result = model.predict(arq_voxels, arq_labels)\n",
    "# Voxels original difference\n",
    "voxels_diff = np.logical_xor(arq_voxels_target > 0, arq_voxels > 0)\n",
    "voxels_diff = voxels_diff.reshape([arq_voxels.shape[0], -1])\n",
    "voxels_diff = np.sum(voxels_diff, 1)\n",
    "# Voxels result difference\n",
    "voxels_result_diff = np.logical_xor(arq_voxels_target > 0, arq_result > 0)\n",
    "voxels_result_diff = voxels_result_diff.reshape([arq_result.shape[0], -1])\n",
    "voxels_result_diff = np.sum(voxels_result_diff, 1)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(voxels_diff, bins=20, alpha=.75, label='missing voxels (before)')\n",
    "plt.hist(voxels_result_diff, bins=20, alpha=.75, label='missing voxels (after)')\n",
    "plt.title('Number of voxels difference')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Show improvement\n",
    "improvement = (voxels_diff - voxels_result_diff) / voxels_diff\n",
    "plt.figure(figsize=(10,2))\n",
    "sns.boxplot(improvement, palette='Set3', linewidth=1, )\n",
    "plt.title('Improvement')\n",
    "plt.xlim(-1.1,1.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_points = 3\n",
    "# radius = 8\n",
    "# model._load_full_test_set(min_points=n_points, max_points=n_points,\n",
    "#                           min_radius=radius, max_radius=radius)\n",
    "model._load_full_test_set(min_points=2, max_points=5,\n",
    "                          min_radius=6, max_radius=10, sphere_chance=.9)\n",
    "voxels, voxels_target, labels = model.full_test_data\n",
    "result = model.predict(voxels, labels)\n",
    "\n",
    "arq_voxels, arq_voxels_target, arq_labels, arq_result = voxels, voxels_target, labels, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = model.label_encoder.transform(['arq'])[0]\n",
    "arq_voxels = voxels[labels == lbl]\n",
    "arq_voxels_target = voxels_target[labels == lbl]\n",
    "arq_labels = labels[labels == lbl]\n",
    "arq_result = model.predict(arq_voxels, arq_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reconstruction.utils.data_prep import get_fractured\n",
    "\n",
    "# def multiplot(i, **kwargs):\n",
    "#     frac = get_fractured(arq_voxels[i], **kwargs)\n",
    "#     r = model.predict(np.expand_dims(arq_voxels[i], 0), np.asarray([labels[i]]))\n",
    "#     plot_reconstruction(frac, r[0]>0)\n",
    "\n",
    "# n = arq_voxels.shape[0]\n",
    "# i = np.random.choice(n) # get random index\n",
    "# plot_vol(arq_voxels_target[i])\n",
    "# multiplot(i)\n",
    "# multiplot(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l1loss = lambda a, b: np.mean(np.abs(a - b))\n",
    "n = arq_voxels.shape[0]\n",
    "\n",
    "# Uncomment the desire choice\n",
    "i = np.random.choice(n) # get random index\n",
    "# i = np.random.choice(np.argsort(improvement)[::-1][:int(n*.07)]) # get good result\n",
    "# i = np.random.choice(np.argsort(improvement)[:int(n*.07)]) # get bad result\n",
    "\n",
    "print('Complete object:')\n",
    "plot_vol(arq_voxels_target[i])\n",
    "n_voxels_target = np.sum(arq_voxels_target[i] == 1)\n",
    "\n",
    "size = 10\n",
    "print('Fractured object (l1=%.4f):' % l1loss(arq_voxels_target[i], arq_voxels[i]))\n",
    "n_voxels = np.sum(arq_voxels[i] == 1)\n",
    "missing_points = n_voxels_target - n_voxels\n",
    "perc_missing = missing_points * 100 / n_voxels_target\n",
    "print(f'Missing voxels: {missing_points} (%.2f%%)' % perc_missing)\n",
    "plot_vol(arq_voxels[i], s=size)\n",
    "\n",
    "print('Reconstruction (l1=%.4f):' % l1loss(arq_voxels_target[i], arq_result[i]))\n",
    "missing_points_result = np.sum((arq_voxels_target[i] + (arq_result[i] > 0)) == 0)\n",
    "extra_points = np.sum((arq_voxels_target[i] + (arq_result[i] > 0)) == 1)\n",
    "print(f'Missing voxels    : {missing_points} -> {missing_points_result}')\n",
    "print(f'Extra voxels added: {extra_points}')\n",
    "plot_reconstruction(arq_voxels[i], arq_result[i], s=size)\n",
    "# plot_reconstruction(arq_voxels[i], arq_voxels_target[i], s=size)\n",
    "rerecon = model.predict_one(arq_result[i], 'arq', decode_label=True)\n",
    "plot_reconstruction(arq_voxels[i], rerecon[0], s=size)\n",
    "rererecon = model.predict_one(arq_result[i], 'arq', decode_label=True)\n",
    "plot_reconstruction(arq_voxels[i], rererecon[0], s=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = voxels.shape[0]\n",
    "\n",
    "# # Uncomment the desire choice\n",
    "# i = np.random.choice(n) # get random index\n",
    "# # i = np.random.choice(np.argsort(improvement)[::-1][:int(n*.07)]) # get good result\n",
    "# # i = np.random.choice(np.argsort(improvement)[:int(n*.07)]) # get bad result\n",
    "\n",
    "# print(f'Complete object ({model.label_encoder.inverse_transform(labels[i])}):')\n",
    "# plot_vol(voxels_target[i])\n",
    "\n",
    "# size = 10\n",
    "# print('Fractured object (l1=%.4f):' % l1loss(voxels_target[i], voxels[i]))\n",
    "# missing_points = np.sum((voxels_target[i] - voxels[i]))\n",
    "# print(f'Missing voxels: {missing_points}')\n",
    "# plot_vol(voxels[i], s=size)\n",
    "\n",
    "# print('Reconstruction (l1=%.4f):' % l1loss(voxels_target[i], result[i]))\n",
    "# missing_points_result = np.sum((voxels_target[i] + (result[i] > 0)) == 0)\n",
    "# extra_points = np.sum((voxels_target[i] + (result[i] > 0)) == 1)\n",
    "# print(f'Missing voxels    : {missing_points} -> {missing_points_result}')\n",
    "# print(f'Extra voxels added: {extra_points}')\n",
    "# plot_reconstruction(voxels[i], result[i], s=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
